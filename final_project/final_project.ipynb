{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A family of hybrid conjugate gradient method with restart procedure for unconstrained optimizations and image restorations**\n",
    "\n",
    "En este código se va a hacer una comparación de los Métodos de Gradiente Conjugado No Lineal con distintas variantes para $\\beta_k$ según las fórmulas de:\n",
    "- FR:  Fletcher-Reeves.\n",
    "- HS:  Hestenes-Stiefel.\n",
    "- PRP: Polak-Ribière-Polak.\n",
    "- DY:  Dai-Yuan.\n",
    "- CD:  Fletcher.\n",
    "- LS:  Liu-Storey.\n",
    "\n",
    "Con la variante propuesta en el artículo: **A family of hybrid conjugate gradient method with restart procedure for unconstrained optimizations and image restorations:**\n",
    "$$\n",
    "\\beta_k^{\\text{JYHL}} = \\frac{2 \\left( \\| g_k \\|^2 - \\theta_k \\frac{\\|g_k\\|}{\\|p_{k-1}\\|} |g_k^T p_{k-1}| \\right)}{g_{k-1}^T \\left( g_{k-1} - d_{k-1} \\right)}.\n",
    "$$\n",
    "**Se realizaron comparaciones para diversos puntos iniciales. Los parámetros usados son los recomendados en el artículo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.- Cargamos las librerías necesarias y definimos las funciones de Hartman, Rosenbrock, Beale y Himmelblau.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(7)\n",
    "\n",
    "def BACKTRAKING_WOLF(a: float, p: float, delta: float,\n",
    "                sigma: float, xk: np.array, f, gradf,\n",
    "                dk: np.array, Nb: int):\n",
    "    \"\"\"\n",
    "    Backtracking line search with the weak Wolfe conditions.\n",
    "    \"\"\"\n",
    "    for i in range(Nb):\n",
    "        if (f(xk + a*dk) <= f(xk) + delta*a*gradf(xk).T @ dk) and (gradf(xk + a*dk).T @ dk >= sigma*gradf(xk).T @ dk):\n",
    "            return a, i\n",
    "        a = p*a\n",
    "    return a, Nb\n",
    "\n",
    "def f_Himmelblau(x: np.array):\n",
    "    return (x[0]**2 + x[1] - 11)**2 + (x[0] + x[1]**2 - 7)**2\n",
    "def grad_Himmelblau(x: np.array):\n",
    "    x1 = 4*x[0]*(x[0]**2 + x[1] - 11) + 2*(x[0] + x[1]**2 - 7)\n",
    "    x2 = 2*(x[0]**2 + x[1] - 11) + 4*x[1]*(x[0] + x[1]**2 - 7)\n",
    "    return np.array([x1,x2], dtype = float)\n",
    "\n",
    "def f_Beale(x: np.array):\n",
    "    return (1.5 - x[0] + x[0]*x[1])**2 + (2.25 - x[0] + x[0]*x[1]**2)**2 + (2.625 - x[0] + x[0]*x[1]**3)**2\n",
    "def grad_Beale(x: np.array):\n",
    "    x1 = 2*(x[1] - 1)*(1.5 - x[0] + x[0]*x[1]) + 2*(x[1]**2 - 1)*(2.25 - x[0] + x[0]*x[1]**2) + 2*(x[1]**3 - 1)*(2.625 - x[0] + x[0]*x[1]**3)\n",
    "    x2 = 2*x[0]*(1.5 - x[0] + x[0]*x[1]) + 4*x[0]*x[1]*(2.25 - x[0] + x[0]*x[1]**2) + 6*x[0]*(x[1]**2)*(2.625 - x[0] + x[0]*x[1]**3)\n",
    "    return np.array([x1,x2], dtype = float)\n",
    "\n",
    "def f_Rosenbrock(x: np.array):\n",
    "    n = len(x)\n",
    "    s = 0\n",
    "    for i in range(n-1):\n",
    "        s = s + 100*(x[i+1] - x[i]**2)**2 + (1 - x[i])**2\n",
    "    return s\n",
    "def grad_Rosenbrock(x: np.array):\n",
    "    n = len(x)\n",
    "    grad = np.zeros(n)\n",
    "    grad[0] = -400*x[0]*(x[1] - x[0]**2) - 2*(1-x[0])\n",
    "    grad[n-1] = 200*(x[n-1] - x[n-2]**2)\n",
    "    for j in range(1,n-1):\n",
    "        grad[j] = 200*(x[j]-x[j-1]**2) - 400*x[j]*(x[j+1] - x[j]**2) - 2*(1-x[j])\n",
    "    return np.array(grad, dtype = float)\n",
    "\n",
    "def f_cuad1(x: np.array, n: int):\n",
    "    A1 = n*np.eye(n, dtype = float) + np.ones([n,n], dtype = float)\n",
    "    b1 = np.ones(n, dtype = float)\n",
    "    return 0.5 * x.T @ A1 @ x - b1.T @ x\n",
    "def gradf_cuad1(x: np.array, n: int):\n",
    "    A1 = n*np.eye(n, dtype = float) + np.ones([n,n], dtype = float)\n",
    "    b1 = np.ones(n, dtype = float)\n",
    "    return A1 @ x - b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Cargamos las funciones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONLINEAR_CONJUGATE_GRADIENT(xk: np.array, f, gradf, maxiter: int,\n",
    "                                 tol: float, a_init: float, p: float,\n",
    "                                 delta: float, sigma: float, Nb: int,\n",
    "                                 METHOD: str):\n",
    "    \"\"\"\n",
    "    THIS FINDS THE MINIMIZER OF f USING THE NON-LINEAR CONJUGATE GRADIENT\n",
    "    METHOD WITH THE SELECTED FORMULA.\n",
    "\n",
    "    Args:\n",
    "    - xk:      initial guess.\n",
    "    - f:       function to minimize.\n",
    "    - gradf:   gradient of the function to minimize.\n",
    "    - maxiter: maximum number of iterations.\n",
    "    - tol:     method tolerance.\n",
    "    - a_init:  initial value for the step size in backtracking.\n",
    "    - p:       reduction factor for the step size in backtracking.\n",
    "    - delta:   parameter for the sufficient descent condition.\n",
    "    - sigma:   parameter for the curvature condition.\n",
    "    - Nb:      maximum number of iterations in backtracking.\n",
    "    - METHOD:  method to use for the conjugate gradient.\n",
    "        - FR:  Fletcher-Reeves.\n",
    "        - HS:  Hestenes-Stiefel.\n",
    "        - PRP: Polak-Ribière-Polak.\n",
    "        - DY:  Dai-Yuan.\n",
    "        - CD:  Fletcher.\n",
    "        - LS:  Liu-Storey.\n",
    "    \n",
    "    Outputs:\n",
    "    - xk:  approach to the minimizer of f.\n",
    "    - gk:  gradient of f at xk.\n",
    "    - k:   number of iterations.\n",
    "    - T/F: if the method converged.\n",
    "    - nr:  number of restarts (bk = 0).\n",
    "    \"\"\"\n",
    "    gk = gradf(xk)\n",
    "    dk = -gk\n",
    "    nr = 0\n",
    "    for k in range(maxiter + 1):\n",
    "        if np.linalg.norm(gk) < tol:\n",
    "            return xk, gk, k, True, nr\n",
    "        ak = BACKTRAKING_WOLF(a = a_init, p = p, delta = delta,\n",
    "                              sigma = sigma, xk = xk, f = f,\n",
    "                              gradf = gradf, dk = dk, Nb = Nb)[0]\n",
    "        xk = xk + ak*dk\n",
    "        gk_n = gradf(xk)\n",
    "        if np.abs(gk_n.T @ gk) < 0.2*np.linalg.norm(gk_n)**2:\n",
    "            if METHOD == 'FR':\n",
    "                bk = (gk_n.T @ gk_n) / (gk.T @ gk)\n",
    "            if METHOD == 'HS':\n",
    "                yk = gk_n - gk\n",
    "                bk = (gk_n.T @ yk) / (dk.T @ yk)\n",
    "            if METHOD == 'PRP':\n",
    "                yk = gk_n - gk\n",
    "                bk = (gk_n.T @ yk) / (gk.T @ gk)\n",
    "            if METHOD == 'DY':\n",
    "                yk = gk_n - gk\n",
    "                bk = (gk_n.T @ yk) / (dk.T @ yk)\n",
    "            if METHOD == 'CD':\n",
    "                bk = -(gk_n.T @ gk_n) / (gk.T @ dk)\n",
    "            if METHOD == 'LS':\n",
    "                yk = gk_n - gk\n",
    "                bk = -(gk_n.T @ yk) / (gk.T @ dk)\n",
    "        else:\n",
    "            bk = 0\n",
    "            nr += 1\n",
    "        dk = -gk_n + bk*dk\n",
    "        gk = gk_n\n",
    "    return xk, gk, maxiter, False, nr\n",
    "\n",
    "def IJYHL_CONJUGATE_GRADIENT(xk: np.array, f, gradf, maxiter: int,\n",
    "                             tol: float, a_init: float, p: float,\n",
    "                             Nb: int, delta: float, sigma: float,\n",
    "                             zeta: float, mu: float, nu: float):\n",
    "    \"\"\"\n",
    "    THIS FINDS THE MINIMIZER OF f USING THE IJYHL CONJUGATE GRADIENT METHOD.\n",
    "    \n",
    "    Args:\n",
    "    - xk:      initial guess.\n",
    "    - f:       function to minimize.\n",
    "    - gradf:   gradient of the function to minimize.\n",
    "    - maxiter: maximum number of iterations.\n",
    "    - tol:     method tolerance.\n",
    "    - a_init:  initial value for the step size in backtracking.\n",
    "    - p:       reduction factor for the step size in backtracking.\n",
    "    - Nb:      maximum number of iterations in backtracking.\n",
    "    - delta:   parameter for the sufficient descent condition.\n",
    "    - sigma:   parameter for the curvature condition.\n",
    "    - zeta:    parameter for the restart direction.\n",
    "    - mu:      parameter for the restart condition.\n",
    "    - nu:      parameter for the restart condition.\n",
    "\n",
    "    Returns:\n",
    "    - xk:  approach to the minimizer of f.\n",
    "    - gk:  gradient of f at xk.\n",
    "    - k:   number of iterations.\n",
    "    - T/F: if the method converged.\n",
    "    - nr:  number of restarts.\n",
    "    \"\"\"\n",
    "    gk = gradf(xk)\n",
    "    dk = -gk\n",
    "    k = 0\n",
    "    nr = 0\n",
    "    while k < maxiter:\n",
    "        if np.linalg.norm(gk) < tol:\n",
    "            return xk, gk, k, True, nr\n",
    "        ak = BACKTRAKING_WOLF(a = a_init, p = p, delta = delta,\n",
    "                              sigma = sigma, xk = xk, f = f,\n",
    "                              gradf = gradf, dk = dk, Nb = Nb)[0]\n",
    "        xk = xk + ak * dk\n",
    "        gk_n = gradf(xk)\n",
    "        thetak = np.abs(gk_n.T @ dk) / (np.linalg.norm(gk_n)*np.linalg.norm(dk))\n",
    "        pk = np.copy(gk)\n",
    "        qk = np.copy(dk)\n",
    "        betak = (2*(np.linalg.norm(gk_n)**2 - thetak * (np.linalg.norm(gk_n))/np.linalg.norm(pk) * np.abs(gk_n.T @ pk) )) / max(gk.T @ (gk - dk),2*np.linalg.norm(gk)**2)\n",
    "        if -mu*np.linalg.norm(gk)**2 <= gk_n.T @ dk <= nu*np.linalg.norm(gk)**2:\n",
    "            dk = -gk_n + betak*dk\n",
    "        else:       \n",
    "            dk = -gk_n + zeta * (gk_n.T @ qk)/(np.linalg.norm(qk)**2) * qk\n",
    "            nr += 1\n",
    "        gk = gk_n\n",
    "        k += 1\n",
    "    return xk, gk, k, False, nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Definición de parámetros.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFININCIÓN DE PARÁMETROS PROPUESTOS POR LOS AUTORES.\n",
    "N     = 2000   # Número de iteraciones.\n",
    "tol   = 10**-6 # Tolerancia.\n",
    "p     = 0.5    # Factor de reducción del tamaño de paso.\n",
    "delta = 0.01   # Parámetro de la condición de descenso suficiente.\n",
    "sigma = 0.1    # Parámetro de la condición de curvatura.\n",
    "Nb    = 500 \n",
    "zeta  = 0.04   # Parámetro para la dirección de reinicio.\n",
    "mu    = 0.9    # Parámetro para la condición de reinicio.\n",
    "nu    = 0.4    # Parámetro para la condición de reinicio.\n",
    "METDS = ['FR', 'HS', 'PRP', 'DY', 'CD', 'LS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Comparación de los métodos para algunos puntos específicos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1. Función de cuadrática 1:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "- $f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^\\top\\mathbf{A}_1\\mathbf{x} - \\mathbf{b}_1^\\top\\mathbf{x}$,\n",
    "  donde $\\mathbf{A}_1$ y $\\mathbf{b}_1$ están definidas como en el Ejercicio 1.\n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{500}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        0.0\n",
      "FR\n",
      "ITERACIONES:  11\n",
      "f(xk):        -0.2499999999999858\n",
      "xk:           [0.05000001 0.05000001 0.05000001 0.05000001] ... [0.05000001 0.05000001 0.05000001 0.05000001]\n",
      "NORMA gk:     7.539457464619588e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    11\n",
      "\n",
      "HS\n",
      "ITERACIONES:  11\n",
      "f(xk):        -0.2499999999999858\n",
      "xk:           [0.05000001 0.05000001 0.05000001 0.05000001] ... [0.05000001 0.05000001 0.05000001 0.05000001]\n",
      "NORMA gk:     7.539457464619588e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    11\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  11\n",
      "f(xk):        -0.2499999999999858\n",
      "xk:           [0.05000001 0.05000001 0.05000001 0.05000001] ... [0.05000001 0.05000001 0.05000001 0.05000001]\n",
      "NORMA gk:     7.539457464619588e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    11\n",
      "\n",
      "DY\n",
      "ITERACIONES:  11\n",
      "f(xk):        -0.2499999999999858\n",
      "xk:           [0.05000001 0.05000001 0.05000001 0.05000001] ... [0.05000001 0.05000001 0.05000001 0.05000001]\n",
      "NORMA gk:     7.539457464619588e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    11\n",
      "\n",
      "CD\n",
      "ITERACIONES:  11\n",
      "f(xk):        -0.2499999999999858\n",
      "xk:           [0.05000001 0.05000001 0.05000001 0.05000001] ... [0.05000001 0.05000001 0.05000001 0.05000001]\n",
      "NORMA gk:     7.539457464619588e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    11\n",
      "\n",
      "LS\n",
      "ITERACIONES:  11\n",
      "f(xk):        -0.2499999999999858\n",
      "xk:           [0.05000001 0.05000001 0.05000001 0.05000001] ... [0.05000001 0.05000001 0.05000001 0.05000001]\n",
      "NORMA gk:     7.539457464619588e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    11\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  11\n",
      "f(xk):        -0.2499999999999858\n",
      "xk:           [0.05000001 0.05000001 0.05000001 0.05000001] ... [0.05000001 0.05000001 0.05000001 0.05000001]\n",
      "NORMA gk:     7.539457464619588e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    0\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "x0 = np.zeros(n, dtype = float)\n",
    "print(\"f(x0):       \", f_cuad1(x0, n))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = lambda x: f_cuad1(x, n=n),\n",
    "                                                       gradf = lambda x: gradf_cuad1(x, n=n),\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_cuad1(xk, n))\n",
    "    print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = lambda x: f_cuad1(x, n=n),\n",
    "                                               gradf = lambda x: gradf_cuad1(x, n=n),\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_cuad1(xk, n))\n",
    "print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        0.0\n",
      "FR\n",
      "ITERACIONES:  29\n",
      "f(xk):        -0.24999999999999828\n",
      "xk:           [0.005 0.005 0.005 0.005] ... [0.005 0.005 0.005 0.005]\n",
      "NORMA gk:     5.669611185421531e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    29\n",
      "\n",
      "HS\n",
      "ITERACIONES:  29\n",
      "f(xk):        -0.24999999999999828\n",
      "xk:           [0.005 0.005 0.005 0.005] ... [0.005 0.005 0.005 0.005]\n",
      "NORMA gk:     5.669611185421531e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    29\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  29\n",
      "f(xk):        -0.24999999999999828\n",
      "xk:           [0.005 0.005 0.005 0.005] ... [0.005 0.005 0.005 0.005]\n",
      "NORMA gk:     5.669611185421531e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    29\n",
      "\n",
      "DY\n",
      "ITERACIONES:  29\n",
      "f(xk):        -0.24999999999999828\n",
      "xk:           [0.005 0.005 0.005 0.005] ... [0.005 0.005 0.005 0.005]\n",
      "NORMA gk:     5.669611185421531e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    29\n",
      "\n",
      "CD\n",
      "ITERACIONES:  29\n",
      "f(xk):        -0.24999999999999828\n",
      "xk:           [0.005 0.005 0.005 0.005] ... [0.005 0.005 0.005 0.005]\n",
      "NORMA gk:     5.669611185421531e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    29\n",
      "\n",
      "LS\n",
      "ITERACIONES:  29\n",
      "f(xk):        -0.24999999999999828\n",
      "xk:           [0.005 0.005 0.005 0.005] ... [0.005 0.005 0.005 0.005]\n",
      "NORMA gk:     5.669611185421531e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    29\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  24\n",
      "f(xk):        -0.24999999999999886\n",
      "xk:           [0.005 0.005 0.005 0.005] ... [0.005 0.005 0.005 0.005]\n",
      "NORMA gk:     6.705522596073266e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    24\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x0 = np.zeros(n, dtype = float)\n",
    "print(\"f(x0):       \", f_cuad1(x0, n))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = lambda x: f_cuad1(x, n=n),\n",
    "                                                       gradf = lambda x: gradf_cuad1(x, n=n),\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_cuad1(xk, n))\n",
    "    print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = lambda x: f_cuad1(x, n=n),\n",
    "                                               gradf = lambda x: gradf_cuad1(x, n=n),\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_cuad1(xk, n))\n",
    "print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        0.0\n",
      "FR\n",
      "ITERACIONES:  301\n",
      "f(xk):        -0.25000000000000494\n",
      "xk:           [0.001 0.001 0.001 0.001] ... [0.001 0.001 0.001 0.001]\n",
      "NORMA gk:     2.913095146047013e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    301\n",
      "\n",
      "HS\n",
      "ITERACIONES:  301\n",
      "f(xk):        -0.25000000000000494\n",
      "xk:           [0.001 0.001 0.001 0.001] ... [0.001 0.001 0.001 0.001]\n",
      "NORMA gk:     2.913095146047013e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    301\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  301\n",
      "f(xk):        -0.25000000000000494\n",
      "xk:           [0.001 0.001 0.001 0.001] ... [0.001 0.001 0.001 0.001]\n",
      "NORMA gk:     2.913095146047013e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    301\n",
      "\n",
      "DY\n",
      "ITERACIONES:  301\n",
      "f(xk):        -0.25000000000000494\n",
      "xk:           [0.001 0.001 0.001 0.001] ... [0.001 0.001 0.001 0.001]\n",
      "NORMA gk:     2.913095146047013e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    301\n",
      "\n",
      "CD\n",
      "ITERACIONES:  301\n",
      "f(xk):        -0.25000000000000494\n",
      "xk:           [0.001 0.001 0.001 0.001] ... [0.001 0.001 0.001 0.001]\n",
      "NORMA gk:     2.913095146047013e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    301\n",
      "\n",
      "LS\n",
      "ITERACIONES:  301\n",
      "f(xk):        -0.25000000000000494\n",
      "xk:           [0.001 0.001 0.001 0.001] ... [0.001 0.001 0.001 0.001]\n",
      "NORMA gk:     2.913095146047013e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    301\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  115\n",
      "f(xk):        -0.24999999999999667\n",
      "xk:           [0.001 0.001 0.001 0.001] ... [0.001 0.001 0.001 0.001]\n",
      "NORMA gk:     3.727561414029029e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    114\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "x0 = np.zeros(n, dtype = float)\n",
    "print(\"f(x0):       \", f_cuad1(x0, n))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = lambda x: f_cuad1(x, n=n),\n",
    "                                                       gradf = lambda x: gradf_cuad1(x, n=n),\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_cuad1(xk, n))\n",
    "    print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = lambda x: f_cuad1(x, n=n),\n",
    "                                               gradf = lambda x: gradf_cuad1(x, n=n),\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_cuad1(xk, n))\n",
    "print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3. Función de Himmelblau para $\\mathbf{x}=(x_1,x_2)$**\n",
    "\n",
    "$$f(\\mathbf{x}) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2. $$\n",
    "$x_0=[2,3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        32.0\n",
      "FR\n",
      "ITERACIONES:  28\n",
      "f(xk):        2.8547190504579647e-17\n",
      "xk:           [3. 2.]\n",
      "NORMA gk:     3.962762538278035e-08\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    26\n",
      "\n",
      "HS\n",
      "ITERACIONES:  24\n",
      "f(xk):        3.7161811384216236e-15\n",
      "xk:           [3.         2.00000001]\n",
      "NORMA gk:     7.055921456967452e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    22\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  22\n",
      "f(xk):        1.0603394093115085e-15\n",
      "xk:           [3.         1.99999999]\n",
      "NORMA gk:     3.4312415430343865e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    19\n",
      "\n",
      "DY\n",
      "ITERACIONES:  24\n",
      "f(xk):        3.7161811384216236e-15\n",
      "xk:           [3.         2.00000001]\n",
      "NORMA gk:     7.055921456967452e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    22\n",
      "\n",
      "CD\n",
      "ITERACIONES:  28\n",
      "f(xk):        2.8547190504579647e-17\n",
      "xk:           [3. 2.]\n",
      "NORMA gk:     3.962762538278035e-08\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    26\n",
      "\n",
      "LS\n",
      "ITERACIONES:  22\n",
      "f(xk):        1.0603394093115085e-15\n",
      "xk:           [3.         1.99999999]\n",
      "NORMA gk:     3.4312415430343865e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    19\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  23\n",
      "f(xk):        2.592460905259686e-15\n",
      "xk:           [3.00000001 2.        ]\n",
      "NORMA gk:     5.75540614556816e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    6\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2,3], dtype = float)\n",
    "n = len(x0)\n",
    "print(\"f(x0):       \", f_Himmelblau(x0))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Himmelblau, gradf = grad_Himmelblau,\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_Himmelblau(xk))\n",
    "    print(\"xk:          \", xk)\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Himmelblau, gradf = grad_Himmelblau,\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_Himmelblau(xk))\n",
    "print(\"xk:          \", xk)\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_0=[2,4]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        130.0\n",
      "FR\n",
      "ITERACIONES:  42\n",
      "f(xk):        2.6508595754176434e-15\n",
      "xk:           [ 3.58442835 -1.84812653]\n",
      "NORMA gk:     7.475969996071486e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    41\n",
      "\n",
      "HS\n",
      "ITERACIONES:  42\n",
      "f(xk):        2.5561816132742194e-15\n",
      "xk:           [ 3.58442835 -1.84812653]\n",
      "NORMA gk:     7.34125052496262e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    41\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  42\n",
      "f(xk):        2.535696626283605e-15\n",
      "xk:           [ 3.58442835 -1.84812653]\n",
      "NORMA gk:     7.311775338809448e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    41\n",
      "\n",
      "DY\n",
      "ITERACIONES:  42\n",
      "f(xk):        2.5561816132742194e-15\n",
      "xk:           [ 3.58442835 -1.84812653]\n",
      "NORMA gk:     7.34125052496262e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    41\n",
      "\n",
      "CD\n",
      "ITERACIONES:  42\n",
      "f(xk):        2.6508595754176434e-15\n",
      "xk:           [ 3.58442835 -1.84812653]\n",
      "NORMA gk:     7.475969996071486e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    41\n",
      "\n",
      "LS\n",
      "ITERACIONES:  42\n",
      "f(xk):        2.535696626283605e-15\n",
      "xk:           [ 3.58442835 -1.84812653]\n",
      "NORMA gk:     7.311775338809448e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    41\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  34\n",
      "f(xk):        4.040807335975879e-15\n",
      "xk:           [ 3.58442835 -1.84812653]\n",
      "NORMA gk:     9.228560518617372e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    32\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2,4], dtype = float)\n",
    "n = len(x0)\n",
    "print(\"f(x0):       \", f_Himmelblau(x0))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Himmelblau, gradf = grad_Himmelblau,\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_Himmelblau(xk))\n",
    "    print(\"xk:          \", xk)\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Himmelblau, gradf = grad_Himmelblau,\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_Himmelblau(xk))\n",
    "print(\"xk:          \", xk)\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4. Función de Beale para $\\mathbf{x}=(x_1,x_2)$**\n",
    "\n",
    "$$f(\\mathbf{x}) = (1.5-x_1 + x_1x_2)^2 + (2.25 - x_1 + x_1x_2^2)^2 + (2.625 - x_1 + x_1x_2^3)^2.$$\n",
    "$x_0=[2,3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        3347.203125\n",
      "FR\n",
      "ITERACIONES:  171\n",
      "f(xk):        4.4824573068808293e-13\n",
      "xk:           [2.99999834 0.49999957]\n",
      "NORMA gk:     7.757485347447975e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    140\n",
      "\n",
      "HS\n",
      "ITERACIONES:  55\n",
      "f(xk):        2.4354752898569687e-13\n",
      "xk:           [2.99999878 0.49999971]\n",
      "NORMA gk:     8.781807369653178e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    43\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  97\n",
      "f(xk):        1.3577389944872002e-14\n",
      "xk:           [2.99999977 0.49999996]\n",
      "NORMA gk:     7.279977549685107e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    81\n",
      "\n",
      "DY\n",
      "ITERACIONES:  55\n",
      "f(xk):        2.4354752898569687e-13\n",
      "xk:           [2.99999878 0.49999971]\n",
      "NORMA gk:     8.781807369653178e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    43\n",
      "\n",
      "CD\n",
      "ITERACIONES:  141\n",
      "f(xk):        7.706808499444559e-13\n",
      "xk:           [3.00000219 0.50000053]\n",
      "NORMA gk:     9.914742174074543e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    113\n",
      "\n",
      "LS\n",
      "ITERACIONES:  88\n",
      "f(xk):        4.472287852839063e-14\n",
      "xk:           [2.99999951 0.4999999 ]\n",
      "NORMA gk:     8.537201994038096e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    72\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  101\n",
      "f(xk):        2.198614363523951e-13\n",
      "xk:           [3.00000116 0.5000003 ]\n",
      "NORMA gk:     7.78869371735405e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    46\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2,3], dtype = float)\n",
    "n = len(x0)\n",
    "print(\"f(x0):       \", f_Beale(x0))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Beale, gradf = grad_Beale,\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_Beale(xk))\n",
    "    print(\"xk:          \", xk)\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Beale, gradf = grad_Beale,\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_Beale(xk))\n",
    "print(\"xk:          \", xk)\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5. Función de Rosenbrock:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "$$ f(\\mathbf{x}) = \\sum_{i=1}^{n-1} \\left[100(x_{i+1} - x_i^2)^2 + (1-x_i)^2 \\right]\n",
    "\\quad n\\geq 2.$$\n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0)\\in \\mathbb{R}^{2}$  \n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{20}$  \n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{40}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        24.199999999999996\n",
      "FR\n",
      "ITERACIONES:  2000\n",
      "f(xk):        4.8699997695794835e-06\n",
      "xk:           [1.0022068  1.00441906]\n",
      "NORMA gk:     0.004179577422755096\n",
      "CONVERGENCIA: False\n",
      "REINICIOS:    1686\n",
      "\n",
      "HS\n",
      "ITERACIONES:  798\n",
      "f(xk):        4.179405031594755e-13\n",
      "xk:           [1.00000065 1.00000129]\n",
      "NORMA gk:     9.790580749730651e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    669\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  1302\n",
      "f(xk):        1.5811876368507815e-14\n",
      "xk:           [1.00000012 1.00000025]\n",
      "NORMA gk:     9.99038787351682e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    1259\n",
      "\n",
      "DY\n",
      "ITERACIONES:  798\n",
      "f(xk):        4.179405031594755e-13\n",
      "xk:           [1.00000065 1.00000129]\n",
      "NORMA gk:     9.790580749730651e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    669\n",
      "\n",
      "CD\n",
      "ITERACIONES:  2000\n",
      "f(xk):        4.8699997695794835e-06\n",
      "xk:           [1.0022068  1.00441906]\n",
      "NORMA gk:     0.004179577422755096\n",
      "CONVERGENCIA: False\n",
      "REINICIOS:    1686\n",
      "\n",
      "LS\n",
      "ITERACIONES:  1011\n",
      "f(xk):        4.632001720649427e-14\n",
      "xk:           [0.99999979 0.99999957]\n",
      "NORMA gk:     9.78630723646544e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    976\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  377\n",
      "f(xk):        9.907624986775363e-14\n",
      "xk:           [1.00000031 1.00000063]\n",
      "NORMA gk:     9.935341821077074e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    326\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2, 1.0], dtype = float)\n",
    "n = len(x0)\n",
    "print(\"f(x0):       \", f_Rosenbrock(x0))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Rosenbrock, gradf = grad_Rosenbrock,\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_Rosenbrock(xk))\n",
    "    print(\"xk:          \", xk)\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Rosenbrock, gradf = grad_Rosenbrock,\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_Rosenbrock(xk))\n",
    "print(\"xk:          \", xk)\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        4598.000000000001\n",
      "FR\n",
      "ITERACIONES:  655\n",
      "f(xk):        2.375761737000349e-13\n",
      "xk:           [1. 1. 1. 1.] ... [1.0000001  1.00000021 1.00000042 1.00000085]\n",
      "NORMA gk:     9.60433011121481e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    507\n",
      "\n",
      "HS\n",
      "ITERACIONES:  953\n",
      "f(xk):        1.938579986045034e-15\n",
      "xk:           [1. 1. 1. 1.] ... [0.99999999 0.99999998 0.99999997 0.99999994]\n",
      "NORMA gk:     8.366403773402635e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    723\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  695\n",
      "f(xk):        9.231232347118253e-14\n",
      "xk:           [1. 1. 1. 1.] ... [0.99999993 0.99999987 0.99999974 0.99999947]\n",
      "NORMA gk:     7.919289857586314e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    531\n",
      "\n",
      "DY\n",
      "ITERACIONES:  953\n",
      "f(xk):        1.938579986045034e-15\n",
      "xk:           [1. 1. 1. 1.] ... [0.99999999 0.99999998 0.99999997 0.99999994]\n",
      "NORMA gk:     8.366403773402635e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    723\n",
      "\n",
      "CD\n",
      "ITERACIONES:  777\n",
      "f(xk):        3.276999946170261e-13\n",
      "xk:           [1. 1. 1. 1.] ... [0.99999988 0.99999975 0.9999995  0.99999901]\n",
      "NORMA gk:     9.972119752303668e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    614\n",
      "\n",
      "LS\n",
      "ITERACIONES:  741\n",
      "f(xk):        2.098237282076769e-13\n",
      "xk:           [1. 1. 1. 1.] ... [1.0000001  1.0000002  1.0000004  1.00000079]\n",
      "NORMA gk:     8.339583626823744e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    579\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  775\n",
      "f(xk):        2.617314192700267e-14\n",
      "xk:           [1. 1. 1. 1.] ... [1.00000003 1.00000007 1.00000014 1.00000028]\n",
      "NORMA gk:     8.939103443927084e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    481\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0], dtype = float)\n",
    "n = len(x0)\n",
    "print(\"f(x0):       \", f_Rosenbrock(x0))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Rosenbrock, gradf = grad_Rosenbrock,\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_Rosenbrock(xk))\n",
    "    print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Rosenbrock, gradf = grad_Rosenbrock,\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_Rosenbrock(xk))\n",
    "print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x0):        9680.000000000002\n",
      "FR\n",
      "ITERACIONES:  1078\n",
      "f(xk):        2.862529124484143e-14\n",
      "xk:           [1. 1. 1. 1.] ... [1.00000004 1.00000007 1.00000014 1.00000029]\n",
      "NORMA gk:     8.374461546464992e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    837\n",
      "\n",
      "HS\n",
      "ITERACIONES:  2000\n",
      "f(xk):        18.42416427892163\n",
      "xk:           [1.00006045 0.99984403 1.00023061 0.99967714] ... [0.01020834 0.01020421 0.01000409 0.00010008]\n",
      "NORMA gk:     3.340162861360251\n",
      "CONVERGENCIA: False\n",
      "REINICIOS:    1545\n",
      "\n",
      "PRP\n",
      "ITERACIONES:  1041\n",
      "f(xk):        3.222880139464832e-15\n",
      "xk:           [1. 1. 1. 1.] ... [0.99999999 0.99999998 0.99999995 0.9999999 ]\n",
      "NORMA gk:     8.344566772496873e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    812\n",
      "\n",
      "DY\n",
      "ITERACIONES:  2000\n",
      "f(xk):        18.42416427892163\n",
      "xk:           [1.00006045 0.99984403 1.00023061 0.99967714] ... [0.01020834 0.01020421 0.01000409 0.00010008]\n",
      "NORMA gk:     3.340162861360251\n",
      "CONVERGENCIA: False\n",
      "REINICIOS:    1545\n",
      "\n",
      "CD\n",
      "ITERACIONES:  1796\n",
      "f(xk):        2.4844540536393238e-14\n",
      "xk:           [1. 1. 1. 1.] ... [0.99999997 0.99999993 0.99999987 0.99999973]\n",
      "NORMA gk:     9.139431942460496e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    1441\n",
      "\n",
      "LS\n",
      "ITERACIONES:  1150\n",
      "f(xk):        2.6861131631909887e-14\n",
      "xk:           [1. 1. 1. 1.] ... [1.00000003 1.00000007 1.00000014 1.00000028]\n",
      "NORMA gk:     8.010328256741944e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    924\n",
      "\n",
      "IJYHL\n",
      "ITERACIONES:  874\n",
      "f(xk):        2.1353889014874224e-13\n",
      "xk:           [1. 1. 1. 1.] ... [1.0000001 1.0000002 1.0000004 1.0000008]\n",
      "NORMA gk:     9.106804374393764e-07\n",
      "CONVERGENCIA: True\n",
      "REINICIOS:    501\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0], dtype = float)\n",
    "n = len(x0)\n",
    "print(\"f(x0):       \", f_Rosenbrock(x0))\n",
    "for i in METDS:\n",
    "    xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Rosenbrock, gradf = grad_Rosenbrock,\n",
    "                                                       maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                       delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                       METHOD = i)\n",
    "    print(i)\n",
    "    print(\"ITERACIONES: \", k)\n",
    "    print(\"f(xk):       \", f_Rosenbrock(xk))\n",
    "    print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "    print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "    print(\"CONVERGENCIA:\", conv)\n",
    "    print(\"REINICIOS:   \", nr)\n",
    "    print(\"\")\n",
    "xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Rosenbrock, gradf = grad_Rosenbrock,\n",
    "                                               maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                               Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                               zeta = zeta, mu = mu, nu = nu)\n",
    "print(\"IJYHL\")\n",
    "print(\"ITERACIONES: \", k)\n",
    "print(\"f(xk):       \", f_Rosenbrock(xk))\n",
    "print(\"xk:          \", xk[:4], \"...\", xk[-4:])\n",
    "print(\"NORMA gk:    \", np.linalg.norm(gk))\n",
    "print(\"CONVERGENCIA:\", conv)\n",
    "print(\"REINICIOS:   \", nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Comparación de los métodos para $20$ puntos aleatorios**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1. Función de Himmelblau para $\\mathbf{x}=(x_1,x_2)$**\n",
    "\n",
    "$$f(\\mathbf{x}) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CONV   ITER\n",
      "FR:       0.8  420.0\n",
      "HS:       0.85  320.95\n",
      "PRP:      0.8  419.95\n",
      "DY:       0.85  320.95\n",
      "CD:       0.8  420.0\n",
      "LS:       0.8  419.95\n",
      "IJYHL:    0.85  319.0\n"
     ]
    }
   ],
   "source": [
    "CONVERGENCIA_METODOS = np.zeros(len(METDS), dtype = 'float')\n",
    "ITERACIONES_METODOS = np.zeros(len(METDS), dtype = 'float')\n",
    "CONVERGENCIA_IJYHL = 0\n",
    "ITERACIONES_IJYHL = 0\n",
    "for j in range(20):\n",
    "    x0 = np.random.uniform(-4, 4, 2)\n",
    "    for i in METDS:\n",
    "        xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Himmelblau, gradf = grad_Himmelblau,\n",
    "                                                           maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                           delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                           METHOD = i)\n",
    "        if conv == True:\n",
    "            CONVERGENCIA_METODOS[METDS.index(i)] += 1\n",
    "        ITERACIONES_METODOS[METDS.index(i)] += k\n",
    "    xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Himmelblau, gradf = grad_Himmelblau,\n",
    "                                                   maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                   Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                                   zeta = zeta, mu = mu, nu = nu)\n",
    "    if conv == True:\n",
    "        CONVERGENCIA_IJYHL += 1\n",
    "    ITERACIONES_IJYHL += k\n",
    "print(\"         CONV   ITER\")\n",
    "print(\"FR:      \", CONVERGENCIA_METODOS[0]/20, \"\", ITERACIONES_METODOS[0]/20)\n",
    "print(\"HS:      \", CONVERGENCIA_METODOS[1]/20, \"\", ITERACIONES_METODOS[1]/20)\n",
    "print(\"PRP:     \", CONVERGENCIA_METODOS[2]/20, \"\", ITERACIONES_METODOS[2]/20)\n",
    "print(\"DY:      \", CONVERGENCIA_METODOS[3]/20, \"\", ITERACIONES_METODOS[3]/20)\n",
    "print(\"CD:      \", CONVERGENCIA_METODOS[4]/20, \"\", ITERACIONES_METODOS[4]/20)\n",
    "print(\"LS:      \", CONVERGENCIA_METODOS[5]/20, \"\", ITERACIONES_METODOS[5]/20)\n",
    "print(\"IJYHL:   \", CONVERGENCIA_IJYHL/20, \"\", ITERACIONES_IJYHL/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2. Función de Beale para $\\mathbf{x}=(x_1,x_2)$**\n",
    "\n",
    "$$f(\\mathbf{x}) = (1.5-x_1 + x_1x_2)^2 + (2.25 - x_1 + x_1x_2^2)^2 + (2.625 - x_1 + x_1x_2^3)^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CONV   ITER\n",
      "FR:       0.65  767.05\n",
      "HS:       0.65  748.05\n",
      "PRP:      0.7  701.15\n",
      "DY:       0.65  748.05\n",
      "CD:       0.7  701.85\n",
      "LS:       0.7  699.35\n",
      "IJYHL:    0.75  573.75\n"
     ]
    }
   ],
   "source": [
    "CONVERGENCIA_METODOS = np.zeros(len(METDS), dtype = 'float')\n",
    "ITERACIONES_METODOS = np.zeros(len(METDS), dtype = 'float')\n",
    "CONVERGENCIA_IJYHL = 0\n",
    "ITERACIONES_IJYHL = 0\n",
    "for j in range(20):\n",
    "    x0 = np.random.uniform(-2, 2, 2)\n",
    "    for i in METDS:\n",
    "        xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Beale, gradf = grad_Beale,\n",
    "                                                           maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                           delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                           METHOD = i)\n",
    "        if conv == True:\n",
    "            CONVERGENCIA_METODOS[METDS.index(i)] += 1\n",
    "        ITERACIONES_METODOS[METDS.index(i)] += k\n",
    "    xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Beale, gradf = grad_Beale,\n",
    "                                                   maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                   Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                                   zeta = zeta, mu = mu, nu = nu)\n",
    "    if conv == True:\n",
    "        CONVERGENCIA_IJYHL += 1\n",
    "    ITERACIONES_IJYHL += k\n",
    "print(\"         CONV   ITER\")\n",
    "print(\"FR:      \", CONVERGENCIA_METODOS[0]/20, \"\", ITERACIONES_METODOS[0]/20)\n",
    "print(\"HS:      \", CONVERGENCIA_METODOS[1]/20, \"\", ITERACIONES_METODOS[1]/20)\n",
    "print(\"PRP:     \", CONVERGENCIA_METODOS[2]/20, \"\", ITERACIONES_METODOS[2]/20)\n",
    "print(\"DY:      \", CONVERGENCIA_METODOS[3]/20, \"\", ITERACIONES_METODOS[3]/20)\n",
    "print(\"CD:      \", CONVERGENCIA_METODOS[4]/20, \"\", ITERACIONES_METODOS[4]/20)\n",
    "print(\"LS:      \", CONVERGENCIA_METODOS[5]/20, \"\", ITERACIONES_METODOS[5]/20)\n",
    "print(\"IJYHL:   \", CONVERGENCIA_IJYHL/20, \"\", ITERACIONES_IJYHL/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3. Función de Rosenbrock:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "$$ f(\\mathbf{x}) = \\sum_{i=1}^{n-1} \\left[100(x_{i+1} - x_i^2)^2 + (1-x_i)^2 \\right]\n",
    "\\quad n\\geq 2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CONV   ITER\n",
      "FR:       0.0  2000.0\n",
      "HS:       0.95  931.75\n",
      "PRP:      0.95  883.25\n",
      "DY:       0.95  931.75\n",
      "CD:       0.0  2000.0\n",
      "LS:       0.95  1025.2\n",
      "IJYHL:    1.0  420.5\n"
     ]
    }
   ],
   "source": [
    "CONVERGENCIA_METODOS = np.zeros(len(METDS), dtype = 'float')\n",
    "ITERACIONES_METODOS = np.zeros(len(METDS), dtype = 'float')\n",
    "CONVERGENCIA_IJYHL = 0\n",
    "ITERACIONES_IJYHL = 0\n",
    "for j in range(20):\n",
    "    x0 = np.random.uniform(-1, 2, 2)\n",
    "    for i in METDS:\n",
    "        xk, gk, k, conv, nr = NONLINEAR_CONJUGATE_GRADIENT(xk = x0, f = f_Rosenbrock, gradf = grad_Rosenbrock,\n",
    "                                                           maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                           delta = delta, sigma = sigma, Nb = Nb,\n",
    "                                                           METHOD = i)\n",
    "        if conv == True:\n",
    "            CONVERGENCIA_METODOS[METDS.index(i)] += 1\n",
    "        ITERACIONES_METODOS[METDS.index(i)] += k\n",
    "    xk, gk, k, conv, nr = IJYHL_CONJUGATE_GRADIENT(xk = x0, f = f_Rosenbrock, gradf = grad_Rosenbrock,\n",
    "                                                   maxiter = N, tol = tol, a_init = 1, p = p,\n",
    "                                                   Nb = Nb, delta = delta, sigma = sigma,\n",
    "                                                   zeta = zeta, mu = mu, nu = nu)\n",
    "    if conv == True:\n",
    "        CONVERGENCIA_IJYHL += 1\n",
    "    ITERACIONES_IJYHL += k\n",
    "print(\"         CONV   ITER\")\n",
    "print(\"FR:      \", CONVERGENCIA_METODOS[0]/20, \"\", ITERACIONES_METODOS[0]/20)\n",
    "print(\"HS:      \", CONVERGENCIA_METODOS[1]/20, \"\", ITERACIONES_METODOS[1]/20)\n",
    "print(\"PRP:     \", CONVERGENCIA_METODOS[2]/20, \"\", ITERACIONES_METODOS[2]/20)\n",
    "print(\"DY:      \", CONVERGENCIA_METODOS[3]/20, \"\", ITERACIONES_METODOS[3]/20)\n",
    "print(\"CD:      \", CONVERGENCIA_METODOS[4]/20, \"\", ITERACIONES_METODOS[4]/20)\n",
    "print(\"LS:      \", CONVERGENCIA_METODOS[5]/20, \"\", ITERACIONES_METODOS[5]/20)\n",
    "print(\"IJYHL:   \", CONVERGENCIA_IJYHL/20, \"\", ITERACIONES_IJYHL/20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
